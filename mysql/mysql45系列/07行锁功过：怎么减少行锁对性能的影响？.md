## 07|行锁功过：怎么减少行锁对性能的影响？

> MySQL的行锁实在引擎层由各个引擎自己实现的。

### 从两阶段锁说起

| 事务A                                                        | 事务B                                     |
| ------------------------------------------------------------ | ----------------------------------------- |
| begin;<BR> update t set k=k+1 where id=1; <BR>update t set k=k+1 where id=2; |                                           |
|                                                              | begin;<BR> update t set k=k+2 where id=1; |
| commit;                                                      |                                           |

事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行；事务A持有两个记录的行锁。**在InnoDB中，行锁是在需要的时候加上的，但并不是不需要的时候就立刻释放。**

**如果你的事务需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。**



### 死锁和死锁检测

>  线程循环资源依赖，都在等待别的线程释放资源。

| 事务A                                     | 事务B                          |
| ----------------------------------------- | ------------------------------ |
| begin; <br>update t set k=k+1 where id=1; | begin;                         |
|                                           | update t set k=k+1 id=2;       |
| update t set k=k+1 id=2;                  |                                |
|                                           | update t set k=k+1 where id=1; |

这个时候事务A在等待事务B释放id=2的行锁，事务B在等待事务A释放id=1的行锁，即进入了死锁状态。出现死锁后两两种策略：

- 直接进入等待，直到超时。超时时间设置参数为：`innodb_lock_wait_timeout`，默认为50s
- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect`设置为on，表示开启这个逻辑。

死锁检测要耗费大量的CPU资源，因为每个新来的被堵住的线程，都要判断还会不会由于自己的加入导致死锁，并发高的情况下，计算量越来越大。

- 一种思路：头痛医头，确保不会出现死锁，关掉死锁检测参数。
- 另一种思路：控制并发度。例如引入消息队列，缓存等中间件。



### 小结

- 两阶段锁： 影响并发的语句，尽量放再事务后面；
- 死锁，死锁超时，死锁检测；业务提前判断不会死锁；引入中间件减少死锁检测压力；



问题：要删除一个表里面的前10000行数据，以下三种方法：

1. 直接执行delete from t limit 10000;
2. 在一个连接中循环执行20次delete from t limit 500;
3. 在20个连接中同时执行delete from t limit 500;

答：第二种相对好些。

- 第一种单句太长，容易引起长/大事务，占用锁时间太长；
- 第三种会造成人为锁冲突；



